{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FNet Model for Melody Generation\n",
    "This model will be trained on melodies from midi data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Song: Ghibli-Spirited-Away-Always-With-Me with 1 parts and 790 notes.\n",
      "Loaded Song: Tonari no Totoro - Kaze no Toori Michi with 1 parts and 681 notes.\n",
      "Loaded Song: Porco Rosso - Doom - Kumo no Wana with 1 parts and 218 notes.\n",
      "Loaded Song: Ghibli-Princess-Mononoke-Theme-Song-Waltz with 1 parts and 1014 notes.\n",
      "Loaded Song: Spirited Away - Inochi no Namae (The Name of Life) with 1 parts and 381 notes.\n",
      "Loaded Song: Spirited Away - Ryuu no Shounen - from the Official Piano Solo Album with 1 parts and 448 notes.\n",
      "Loaded Song: Spirited Away - The Sixth Station (1) with 1 parts and 407 notes.\n",
      "Loaded Song: Ghibli-Porco-Rosso-Bygone-Days-Waltz with 1 parts and 657 notes.\n",
      "Loaded Song: Ghibli-Ponyo-on-the-Cliff-by-the-Sea-Waltz with 1 parts and 727 notes.\n",
      "Loaded Song: Nisemonogatari - Tetsu Kamen OST with 1 parts and 241 notes.\n",
      "Loaded Song: Princess Mononoke - Ashitaka to San (Db major) with 1 parts and 464 notes.\n",
      "Loaded Song: Ghibli-Laputa-The-Girl-Who-Fell-From-The-Sky-Waltz with 1 parts and 1190 notes.\n",
      "Loaded Song: Bakemonogatari - Kimi no Shiranai Monogatari (1) with 2 parts and 2681 notes.\n",
      "Loaded Song: Porco Rosso - Doom - Kumo no Wana with 1 parts and 218 notes.\n",
      "Loaded Song: Ghibli-Spirited-Away-Always-With-Me with 1 parts and 790 notes.\n",
      "Total number of notes: 10907\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from random import choice\n",
    "\n",
    "from song import Song\n",
    "\n",
    "\n",
    "num_of_songs = 15\n",
    "\n",
    "midi_dir = \"../examples/ghibli_dataset\"\n",
    "files = listdir(midi_dir)\n",
    "\n",
    "songs = []\n",
    "\n",
    "while num_of_songs > 0:\n",
    "    s = Song(midi_dir + \"/\" + choice(files))\n",
    "    if s.parsed:\n",
    "        songs.append(s)\n",
    "        num_of_songs-= 1\n",
    "        \n",
    "total_notes = sum([s.num_notes for s in songs])\n",
    "print(f\"Total number of notes: {total_notes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update\n",
    "# Create scale strings\n",
    "# from music21.stream import Part\n",
    "# from music21.duration import Duration\n",
    "# from music21.note import Note\n",
    "\n",
    "# from instrument import Instrument\n",
    "\n",
    "# base_scale = ['C', 'D', 'E', 'F', 'G', 'A', 'B']\n",
    "\n",
    "# scales = []\n",
    "\n",
    "# base_part = Part()\n",
    "# for i, n in enumerate(base_scale):\n",
    "#     # Limitation: each scale will have the same random attributes as the base\n",
    "#     note = Note(n)\n",
    "#     note.quarterLength = choice([1/2, 1/4, 1/8])\n",
    "#     note.volume.velocity = choice(range(60,100))\n",
    "#     note.offset = i\n",
    "#     base_part.append(note)\n",
    "\n",
    "# for i in range(12):\n",
    "#     base_part = base_part.transpose(i)\n",
    "#     scales.append(Instrument(base_part))\n",
    "# print(len(scales))\n",
    "# print(scales[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 55 2 75 2 75 47 615 2 75 1 15 48 715 0 1 2 225 51 54 0 1 2 225 39 24 0 1 2 225 38 55 2 125 2 275 45 25 1 5 1 35 53 4/4 25 2 75 0 0 53 54 0 1 0 0 39 24 0 1 0 0 38 55 0 1 0 0 45 715 1 5 1 15 44 524 0 1 2 225 41 24 0 1 2 225 43 615 1 15 2 225 47 25 1 5 1 35 52\n",
      "4/4 524 0 1 0 0 41 24 0 1 0 0 43 25 3 167 0 0 52 615 2 25 0 1 55 314 0 2 0 2 31 714 0 1 0 2 46 55 0 1 0 2 50 54 2 175 2 225 35 315 2 25 2 275 46 315 1 5 1 35 54 4/4 314 2 75 0 0 31 315 3 167 0 0 54 54 2 75 0 0 35 525 1 5 2 75 53 55 1 25 1 15 49 614 2 175 2 225 36 524 0 1 2 225 35 713 0 1 2 225 30 24 2 175 2 225 44\n",
      "1512\n",
      "1512\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "# Dataset augmentation\n",
    "input_seq = []\n",
    "output_seq = []\n",
    "\n",
    "MAX_IN_MEASURES = 2\n",
    "MAX_OUT_MEASURES = 2\n",
    "STEP = 1\n",
    "\n",
    "for song in songs:\n",
    "    for part in song.parts:\n",
    "        i = 0\n",
    "        while i < len(part.measures):\n",
    "            in_measures = randint(1, MAX_IN_MEASURES)\n",
    "            out_measures = randint(1, MAX_OUT_MEASURES)\n",
    "            if i + in_measures + out_measures < len(part.measures):\n",
    "                in_seq = []\n",
    "                for j in range(in_measures):\n",
    "                    in_seq.append(str(part.measures[i + j]))\n",
    "                \n",
    "                out_seq = []\n",
    "                for j in range(out_measures):\n",
    "                    out_seq.append(str(part.measures[i + in_measures + j]))\n",
    "                input_seq.append(\" \".join(in_seq))\n",
    "                output_seq.append(\" \".join(out_seq))\n",
    "            i += STEP\n",
    "\n",
    "print(input_seq[0])\n",
    "print(output_seq[0])\n",
    "print(len(input_seq))\n",
    "print(len(output_seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate vocab\n",
    "# vocab = []\n",
    "\n",
    "# for i in range(16):\n",
    "#     for j in range(16):  \n",
    "#         vocab.append(f\"{i+1}/{j+1}\")\n",
    "# for i in range(10000):\n",
    "#     vocab.append(str(i))\n",
    "\n",
    "# vocab = \" \".join(vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonathan/miniforge3/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import FNetForNextSentencePrediction, FNetTokenizerFast, FNetConfig\n",
    "\n",
    "# Tokenize the prompts and responses\n",
    "tokenizer = FNetTokenizerFast.from_pretrained(\"google/fnet-base\")\n",
    "encoded_input = tokenizer(input_seq, add_special_tokens=True, return_tensors='pt', padding='max_length', truncation=True, max_length=512)\n",
    "encoded_output = tokenizer(output_seq, add_special_tokens=True, return_tensors='pt', padding='max_length', truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = FNetConfig(\n",
    "    vocab_size=9999, # the number of unique tokens in your dataset\n",
    ")\n",
    "# Create an instance of the model\n",
    "model = FNetForNextSentencePrediction(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments \n",
    "\n",
    "# Training\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=5e-5)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    evaluation_strategy='steps',     # evaluation strategy\n",
    "    evaluation_steps=100,            # number of steps between evaluations\n",
    "    per_device_train_batch_size=32,  # batch size\n",
    "    per_device_eval_batch_size=32,   # batch size for evaluation\n",
    "    weight_decay=0.01,               # weight decay\n",
    "    learning_rate=5e-5,              # learning rate\n",
    "    num_train_epochs=5,              # number of training epochs\n",
    "    logging_dir='./logs',            # directory to save logs\n",
    "    logging_steps=100                # number of steps between logging events\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    data_collator=data_collator,\n",
    "    optimizers=(optimizer,),\n",
    "    loss_fn=loss_fn\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
